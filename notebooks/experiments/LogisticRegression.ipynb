{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a028d859",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۰) وارد کردن کتابخانه‌های مورد نیاز (Logistic Regression)\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در این نوتبوک هدف ما آموزش و تنظیم (Tuning) مدل <b>Logistic Regression</b> است.  \n",
    "لجستیک رگرشن یک مدل خطی برای طبقه‌بندی است که به عنوان یک مدل پایه (Baseline) بسیار رایج و قابل دفاع محسوب می‌شود.\n",
    "<br><br>\n",
    "نکته مهم این است که Logistic Regression نسبت به مقیاس ویژگی‌ها حساس است؛ بنابراین در این نوتبوک از <b>Scaling</b> (مانند <code>MinMaxScaler</code> یا StandardScaler) داخل <code>Pipeline</code> استفاده می‌کنیم تا:\n",
    "<br>\n",
    "- ویژگی‌ها هم‌مقیاس شوند،\n",
    "<br>\n",
    "- و در Cross-Validation نشت اطلاعات (Data Leakage) رخ ندهد.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cde2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, make_scorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737831a7",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۱) خواندن داده‌های پیش‌پردازش‌شده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در نوتبوک پیش‌پردازش، داده‌ها پاکسازی و به فرم عددی مناسب برای مدل‌سازی تبدیل شده‌اند.  \n",
    "در این نوتبوک فقط روی مدل Logistic Regression تمرکز می‌کنیم؛ بنابراین داده آماده را از فایل می‌خوانیم تا ساختار پروژه مرتب و قابل توسعه باشد.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39936755",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../data/train_processed.csv\")\n",
    "print(\"train:\", train_data.shape)\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d87f1b",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۲) جدا کردن ویژگی‌ها (X) و متغیر هدف (y)\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "برای آموزش مدل باید ستون هدف <code>TripReason</code> را به عنوان y جدا کنیم و سایر ستون‌ها را به عنوان ویژگی‌های ورودی X در نظر بگیریم.  \n",
    "این کار باعث می‌شود ورودی مدل دقیقاً شامل ویژگی‌ها باشد و از بروز خطای مفهومی جلوگیری شود.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d381f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=[\"TripReason\"])\n",
    "y = train_data[\"TripReason\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9925f432",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۳) تقسیم داده به Train و Validation\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "برای ارزیابی واقعی مدل، بخشی از داده را به عنوان Validation کنار می‌گذاریم.  \n",
    "همچنین با استفاده از <code>stratify</code> نسبت کلاس‌ها در Train و Validation مشابه می‌ماند و ارزیابی منصفانه‌تر می‌شود.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe = Pipeline(steps=[\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=5000))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c15e655",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۴) ساخت Pipeline (Scaling + Logistic Regression)\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "Logistic Regression یک مدل خطی است و در فرآیند یادگیری به مقیاس ویژگی‌ها حساس است؛  \n",
    "اگر یک ویژگی دامنه بسیار بزرگ‌تری داشته باشد، می‌تواند روی یادگیری اثر غالب بگذارد.\n",
    "<br><br>\n",
    "به همین دلیل از Scaling استفاده می‌کنیم.  \n",
    "همچنین Scaling را داخل <code>Pipeline</code> قرار می‌دهیم تا در Cross-Validation، scaler فقط روی داده Train هر fold fit شود و نشت اطلاعات (Data Leakage) رخ ندهد.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_macro = make_scorer(f1_score, average=\"macro\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163eeef",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۵) معیار ارزیابی: Macro F1-Score\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "برای ارزیابی مدل از <code>F1-Score</code> استفاده می‌کنیم چون معیار داوری همین است.  \n",
    "در این نوتبوک از <b>Macro-F1</b> استفاده می‌کنیم تا هر کلاس وزن برابر داشته باشد و در صورت نامتوازن بودن داده، مدل فقط روی کلاس غالب خوب عمل نکند.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a935195",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
    "mean_scores = []\n",
    "\n",
    "for C in C_list:\n",
    "    log_pipe.set_params(model__C=C, model__penalty=\"l2\", model__solver=\"lbfgs\")\n",
    "    scores = cross_val_score(log_pipe, X_train, y_train, cv=cv, scoring=f1_macro)\n",
    "    mean_scores.append(scores.mean())\n",
    "    print(f\"C={C:<5} => CV Macro-F1: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n",
    "\n",
    "best_C = C_list[int(np.argmax(mean_scores))]\n",
    "print(\"\\nBest C (L2, lbfgs):\", best_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be64bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(C_list, mean_scores, marker=\"o\")\n",
    "plt.xscale(\"log\")\n",
    "plt.title(\"Logistic Regression: C vs CV Macro-F1 (L2, lbfgs)\")\n",
    "plt.xlabel(\"C (log scale)\")\n",
    "plt.ylabel(\"Macro-F1\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e8d2da",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۶) تنظیم پارامترهای Logistic Regression با Cross-Validation\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "برای اینکه تست ما واقعی باشد، فقط یک بار مدل را آموزش نمی‌دهیم.  \n",
    "پارامترهای مهم Logistic Regression را بررسی می‌کنیم:\n",
    "<br>\n",
    "- <code>C</code>: میزان منظم‌سازی (Regularization).  \n",
    "C کوچک‌تر یعنی منظم‌سازی بیشتر (مدل ساده‌تر)، و C بزرگ‌تر یعنی منظم‌سازی کمتر (مدل پیچیده‌تر).\n",
    "<br>\n",
    "- <code>penalty</code>: نوع منظم‌سازی (L1 یا L2)\n",
    "<br>\n",
    "- <code>solver</code>: الگوریتم بهینه‌سازی که باید با penalty سازگار باشد.\n",
    "<br><br>\n",
    "برای انتخاب بهترین ترکیب، از Cross-Validation استفاده می‌کنیم تا نتیجه به یک تقسیم‌بندی خاص وابسته نباشد.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list = [0.01, 0.1, 1, 10]\n",
    "settings = [\n",
    "    {\"penalty\": \"l2\", \"solver\": \"lbfgs\"},\n",
    "    {\"penalty\": \"l2\", \"solver\": \"liblinear\"},\n",
    "    {\"penalty\": \"l1\", \"solver\": \"liblinear\"},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for s in settings:\n",
    "    for C in C_list:\n",
    "        log_pipe.set_params(\n",
    "            model__C=C,\n",
    "            model__penalty=s[\"penalty\"],\n",
    "            model__solver=s[\"solver\"]\n",
    "        )\n",
    "        scores = cross_val_score(log_pipe, X_train, y_train, cv=cv, scoring=f1_macro)\n",
    "        results.append({\n",
    "            \"C\": C,\n",
    "            \"penalty\": s[\"penalty\"],\n",
    "            \"solver\": s[\"solver\"],\n",
    "            \"cv_mean_f1\": scores.mean(),\n",
    "            \"cv_std_f1\": scores.std()\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"cv_mean_f1\", ascending=False)\n",
    "results_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = results_df.iloc[0]\n",
    "best_C = best_row[\"C\"]\n",
    "best_penalty = best_row[\"penalty\"]\n",
    "best_solver = best_row[\"solver\"]\n",
    "\n",
    "best_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea2884",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۷) آموزش بهترین مدل و ارزیابی نهایی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "پس از انتخاب بهترین پارامترها، مدل نهایی را با همان تنظیمات آموزش می‌دهیم و روی داده Validation ارزیابی می‌کنیم.  \n",
    "در کنار F1-Score، ماتریس درهم‌ریختگی و گزارش طبقه‌بندی را نیز نمایش می‌دهیم تا رفتار مدل در هر کلاس مشخص شود.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee05a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_log = Pipeline(steps=[\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"model\", LogisticRegression(\n",
    "        C=float(best_C),\n",
    "        penalty=str(best_penalty),\n",
    "        solver=str(best_solver),\n",
    "        max_iter=5000\n",
    "    ))\n",
    "])\n",
    "\n",
    "final_log.fit(X_train, y_train)\n",
    "pred = final_log.predict(X_val)\n",
    "\n",
    "print(\"Validation Macro-F1:\", f1_score(y_val, pred, average=\"macro\"))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
