{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73a1693",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۰) وارد کردن کتابخانه‌های مورد نیاز (XGBoost)\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در این نوتبوک هدف ما آموزش و تنظیم (Tuning) مدل <b>XGBoost</b> است.  \n",
    "XGBoost یک الگوریتم قدرتمند مبتنی بر درخت‌های تصمیم و روش <b>Boosting</b> است که معمولاً در مسائل جدولی (Tabular Data) عملکرد بسیار خوبی دارد.\n",
    "<br><br>\n",
    "برخلاف مدل‌هایی مثل KNN، XGBoost معمولاً به Scaling حساس نیست؛ چون تصمیم‌گیری آن بر اساس تقسیم‌بندی درختی انجام می‌شود نه فاصله.\n",
    "<br><br>\n",
    "در ادامه، علاوه بر آموزش مدل، چندین پارامتر مهم را تست می‌کنیم تا بهترین تنظیمات ممکن بر اساس معیار <code>F1-Score</code> به دست آید.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, make_scorer\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f298d",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۱) خواندن داده‌های پیش‌پردازش‌شده\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در نوتبوک پیش‌پردازش، داده‌ها پاکسازی و تبدیل به فرم عددی شده‌اند.  \n",
    "در این نوتبوک تمرکز فقط روی مدل‌سازی است؛ بنابراین داده‌های آماده را از فایل می‌خوانیم تا پروژه ما:\n",
    "<br>\n",
    "- مرتب و ماژولار باشد،\n",
    "<br>\n",
    "- و بتوانیم برای هر مدل یک نوتبوک مستقل داشته باشیم.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc600e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../../data/train_processed.csv\")\n",
    "print(\"train:\", train_data.shape)\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fefbf3",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۲) جدا کردن ویژگی‌ها (X) و متغیر هدف (y)\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "برای مدل‌سازی باید ستون هدف <code>TripReason</code> را به عنوان y جدا کنیم و باقی ستون‌ها را به عنوان ویژگی‌های ورودی X در نظر بگیریم.  \n",
    "این کار از ورود ناخواسته ستون هدف به ورودی مدل جلوگیری کرده و روند آموزش را شفاف می‌کند.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf753ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=[\"TripReason\"])\n",
    "y = train_data[\"TripReason\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c5d7c",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۳) تقسیم داده به Train و Validation\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "برای ارزیابی واقعی مدل، بخشی از داده را به عنوان Validation کنار می‌گذاریم.  \n",
    "با استفاده از <code>stratify</code> نسبت کلاس‌ها در هر دو بخش مشابه می‌ماند تا ارزیابی منصفانه‌تر و پایدارتر شود.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6618b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = y.nunique()\n",
    "\n",
    "if n_classes == 2:\n",
    "    objective = \"binary:logistic\"\n",
    "    eval_metric = \"logloss\"\n",
    "else:\n",
    "    objective = \"multi:softprob\"\n",
    "    eval_metric = \"mlogloss\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b2446",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۴) معیار ارزیابی: Macro F1-Score\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "چون معیار داوری مسئله <code>F1-Score</code> است، ما نیز مدل را با همین معیار ارزیابی می‌کنیم.  \n",
    "از <b>Macro-F1</b> استفاده می‌کنیم تا هر کلاس وزن برابر داشته باشد و مدل فقط روی کلاس غالب خوب عمل نکند.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective=objective,\n",
    "    eval_metric=eval_metric,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "if n_classes > 2:\n",
    "    baseline_xgb.set_params(num_class=n_classes)\n",
    "\n",
    "baseline_xgb.fit(X_train, y_train)\n",
    "pred_base = baseline_xgb.predict(X_val)\n",
    "\n",
    "print(\"Baseline Validation Macro-F1:\", f1_score(y_val, pred_base, average=\"macro\"))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, pred_base))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, pred_base))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9339636",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۵) آموزش مدل پایه (Baseline) با XGBoost\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در ابتدا یک مدل پایه با تنظیمات معقول آموزش می‌دهیم تا یک نقطه شروع داشته باشیم.  \n",
    "سپس در مراحل بعد با تنظیم پارامترها (Tuning) تلاش می‌کنیم عملکرد را بهبود دهیم.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2515f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_macro = make_scorer(f1_score, average=\"macro\")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [200, 300, 400, 600, 800],\n",
    "    \"max_depth\": [3, 5, 7, 9, 12],\n",
    "    \"learning_rate\": [0.03, 0.05, 0.08, 0.1, 0.15],\n",
    "    \"subsample\": [0.6, 0.75, 0.85, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.75, 0.85, 1.0],\n",
    "    \"min_child_weight\": [1, 3, 5, 7, 10],\n",
    "    \"gamma\": [0, 0.2, 0.5, 1, 2],\n",
    "    \"reg_alpha\": [0, 0.01, 0.1, 1],\n",
    "    \"reg_lambda\": [1, 1.5, 2, 3]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42,\n",
    "    objective=objective,\n",
    "    eval_metric=eval_metric,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "if n_classes > 2:\n",
    "    xgb.set_params(num_class=n_classes)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,              # تعداد تست‌ها (می‌تونی 40 هم بزاری ولی کندتر میشه)\n",
    "    scoring=f1_macro,\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV Macro-F1:\", search.best_score_)\n",
    "print(\"Best Params:\\n\", search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e0892",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۶) تنظیم پارامترهای XGBoost (Tuning) با Cross-Validation\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "XGBoost پارامترهای زیادی دارد و انتخاب دستی بهترین ترکیب همیشه ساده نیست.  \n",
    "برای اینکه تست ما واقعی و قابل دفاع باشد، از <b>Cross-Validation</b> به همراه <b>RandomizedSearch</b> استفاده می‌کنیم تا چندین ترکیب از پارامترها بررسی شود.\n",
    "<br><br>\n",
    "برخی پارامترهای مهم:\n",
    "<br>\n",
    "- <code>n_estimators</code>: تعداد درخت‌ها\n",
    "<br>\n",
    "- <code>max_depth</code>: عمق هر درخت (کنترل پیچیدگی)\n",
    "<br>\n",
    "- <code>learning_rate</code>: نرخ یادگیری (Trade-off با n_estimators)\n",
    "<br>\n",
    "- <code>subsample</code> و <code>colsample_bytree</code>: جلوگیری از overfitting\n",
    "<br>\n",
    "- <code>min_child_weight</code> و <code>gamma</code>: کنترل سخت‌گیری برای split ها\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b2eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = search.best_estimator_\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "pred = best_xgb.predict(X_val)\n",
    "print(\"Final Validation Macro-F1:\", f1_score(y_val, pred, average=\"macro\"))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val, pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c09da",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۷) ارزیابی مدل نهایی و تحلیل نتایج\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "پس از یافتن بهترین پارامترها، مدل نهایی را با همان تنظیمات روی داده Train آموزش می‌دهیم و روی Validation ارزیابی می‌کنیم.  \n",
    "علاوه بر F1-Score، ماتریس درهم‌ریختگی و گزارش طبقه‌بندی نمایش داده می‌شود تا نوع خطاهای مدل مشخص شود.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_xgb.feature_importances_\n",
    "feat_imp = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"importance\": importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "feat_imp.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 20\n",
    "tmp = feat_imp.head(topk).iloc[::-1]  # برعکس برای زیبایی\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(tmp[\"feature\"], tmp[\"importance\"])\n",
    "plt.title(\"Top 20 Feature Importances (XGBoost)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.grid(True, axis=\"x\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e07c7",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "۸) تحلیل اهمیت ویژگی‌ها (Feature Importance)\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "یکی از مزیت‌های مدل‌های مبتنی بر درخت امکان بررسی اهمیت ویژگی‌هاست.  \n",
    "در این بخش اهمیت ویژگی‌ها را استخراج می‌کنیم تا بفهمیم کدام ویژگی‌ها بیشترین نقش را در پیش‌بینی TripReason داشته‌اند.\n",
    "</font>\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
