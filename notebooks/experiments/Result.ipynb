{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b612e4",
   "metadata": {},
   "source": [
    "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "نتیجه‌گیری نهایی مقایسه مدل‌های یادگیری ماشین\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در این پژوهش، عملکرد پنج الگوریتم SVM، KNN، Logistic Regression، Random Forest و XGBoost بر روی مجموعه‌داده‌ای شامل ۱۰٬۰۰۰ نمونه مورد ارزیابی قرار گرفت. معیار اصلی ارزیابی، Macro-F1 به‌همراه ماتریس درهم‌ریختگی، دقت (Accuracy)، Precision و Recall بوده است.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "بر اساس نتایج به‌دست‌آمده، الگوریتم XGBoost با مقدار Macro-F1 حدود 0.8365 بهترین عملکرد را در میان مدل‌های بررسی‌شده نشان داد. الگوریتم KNN عملکردی بسیار نزدیک به XGBoost داشته است (Macro-F1 حدود 0.8350)، در حالی که Logistic Regression با دقت کلی 0.78 و Macro-F1 برابر با 0.76 نسبت به دو مدل قبلی عملکرد ضعیف‌تری ارائه داده است.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "تحلیل شاخص‌های Precision و Recall نشان می‌دهد که XGBoost توانسته تعادل مناسبی میان دو کلاس برقرار کند و در کلاس مثبت (1) نیز Recall بالایی داشته باشد. با توجه به اینکه معیار Macro-F1 میانگین عملکرد مدل در هر دو کلاس را بدون توجه به توزیع داده‌ها نشان می‌دهد، این مدل از نظر تعادل و پایداری عملکرد، برتری نسبی خود را حفظ کرده است.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در خصوص الگوریتم SVM باید توجه داشت که به دلیل پیچیدگی محاسباتی و زمان‌بر بودن فرآیند آموزش، این مدل بر روی تعداد کمتری از داده‌ها آموزش داده شده است. این موضوع می‌تواند منجر به کاهش قابلیت تعمیم‌پذیری و در نتیجه افت دقت نهایی شده باشد. در صورت آموزش SVM بر روی کل داده‌ها و با تنظیم مناسب ابرپارامترها، احتمال بهبود عملکرد آن وجود دارد.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در مجموع، با در نظر گرفتن معیارهای ارزیابی، تعادل میان Precision و Recall و همچنین کارایی محاسباتی، مدل XGBoost به‌عنوان گزینه نهایی و بهینه برای این مسئله انتخاب می‌شود؛ چرا که علاوه بر دستیابی به بالاترین مقدار Macro-F1، عملکردی پایدار و متوازن در هر دو کلاس ارائه داده است.\n",
    "</font>\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
